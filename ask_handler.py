from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain
from dotenv import load_dotenv
import os

# Ortam deÄŸiÅŸkenlerini yÃ¼kle (.env dosyasÄ±ndan)
load_dotenv()
api_key = os.environ.get("OPENAI_API_KEY")

# FAISS vektÃ¶r veritabanÄ±nÄ± yÃ¼kle
embedding = OpenAIEmbeddings(openai_api_key=api_key)
vectorstore = FAISS.load_local(
    "sibel_faiss_index", embedding, allow_dangerous_deserialization=True
)

# GPT modeli
llm = OpenAI(openai_api_key=api_key, temperature=0.4)

# QA zincirini yÃ¼kle
qa_chain = load_qa_chain(llm, chain_type="stuff")

# Sistem yÃ¶nlendirmesi: TÃ¼rkÃ§e ve net cevap ver
system_prompt = (
    "LÃ¼tfen aÅŸaÄŸÄ±daki dÃ¶kÃ¼manlarÄ± kullanarak kullanÄ±cÄ±ya TÃœRKÃ‡E, sade ve anlaÅŸÄ±lÄ±r ÅŸekilde cevap ver. "
    "VarsayÄ±mda bulunma, sadece belgede varsa yanÄ±tla. Uyumlu, samimi ve uzman bir danÄ±ÅŸman gibi konuÅŸ."
)

# Soruya cevap veren fonksiyon
def answer_question(question):
    docs = vectorstore.similarity_search(question, k=3)
    full_prompt = f"{system_prompt}\nSoru: {question}"
    response = qa_chain.run(input_documents=docs, question=full_prompt)
    return response

# Terminalden test etmek istersen
if __name__ == "__main__":
    print("ğŸŸ£ SibelGPT HazÄ±r. Soru sormak iÃ§in yaz, Ã§Ä±kmak iÃ§in 'Ã§Ä±k' yaz.")
    while True:
        question = input("â“ Soru sor: ")
        if question.lower() in ["Ã§Ä±k", "exit", "q"]:
            break
        answer = answer_question(question)
        print("ğŸ¤– SibelGPT:", answer)
