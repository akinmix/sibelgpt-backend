from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from dotenv import load_dotenv
import os

from langchain_community.document_loaders import DirectoryLoader
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# Ortam deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# Markdown dosyalarÄ±nÄ± yÃ¼kle
loader = DirectoryLoader("markdowns", glob="*.md")
documents = loader.load()

# Metinleri parÃ§ala â€“ chunk ayarÄ± yÃ¼kseltildi
text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=50)
texts = text_splitter.split_documents(documents)

# VektÃ¶r veri tabanÄ± oluÅŸtur â€“ Chroma
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
db = Chroma.from_documents(texts, embeddings, persist_directory="chroma_db")

# Retriever ince ayar: daha iyi eÅŸleÅŸme iÃ§in k ve skor eÅŸiÄŸi
retriever = db.as_retriever(search_kwargs={"k": 5, "score_threshold": 0.5})

# LangChain QA zinciri
qa = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(openai_api_key=openai_api_key),
    retriever=retriever
)

# FastAPI baÅŸlat
app = FastAPI()

# CORS izinleri
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# /chat endpoint (SibelGPT frontend iÃ§in)
@app.post("/chat")
async def chat_endpoint(request: Request):
    data = await request.json()
    message = data.get("question", "")

    if not message:
        return JSONResponse(content={"error": "Soru eksik."}, status_code=400)

    answer = qa.invoke(message)
    custom_closing = "\n\nğŸ‘‰ EÄŸer ilginizi Ã§eken bir ilan varsa ilan numarasÄ±nÄ± sorarak detaylÄ± bilgi alabilirsiniz."
    return {"reply": answer + custom_closing}
