from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from dotenv import load_dotenv
import os

from langchain_community.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.chains.question_answering import load_qa_chain

# Ortam deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# Markdown dosyalarÄ±nÄ± yÃ¼kle
loader = DirectoryLoader("markdowns", glob="*.md")
documents = loader.load()

# Chunk ayarlarÄ±
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
texts = text_splitter.split_documents(documents)
print(f"\nâœ… Toplam yÃ¼klÃ¼ dÃ¶kÃ¼man: {len(texts)}")

# VektÃ¶r veritabanÄ±
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
db = Chroma.from_documents(texts, embeddings, persist_directory="chroma_db")
retriever = db.as_retriever()

# âœ… DOÄRU FORMATTA PROMPT: context ve question iÃ§ermeli
custom_prompt_template = """
AÅŸaÄŸÄ±daki baÄŸlama (context) dayanarak, kullanÄ±cÄ±nÄ±n sorusuna (soru) cevap ver:

- Uzun paragraflar yazma, her sonucu madde madde sÄ±ralÄ± olarak ver.
- Her Ã¶neri iÃ§in ÅŸu bilgileri ver:
    - Ä°lan NumarasÄ±
    - Lokasyon (semt/mahalle)
    - Oda sayÄ±sÄ±
    - mÂ²
    - Kat durumu
    - Fiyat
    - (Varsa) ekstra bilgi: deniz manzarasÄ±, krediye uygunluk, yeni bina, site iÃ§i vb.
- En az 2, mÃ¼mkÃ¼nse 3 alternatif sun.
- KullanÄ±cÄ±yÄ± baÅŸka siteye, danÄ±ÅŸmana veya dÄ±ÅŸ kaynaÄŸa yÃ¶nlendirme.
- CevabÄ±n sonunda ÅŸunu yaz:
  â€œDilersen daha fazla seÃ§enek de sunabilirim, baÅŸka kriterlerin varsa hemen yazabilirsin.â€

BaÄŸlam:
{context}

Soru:
{question}
"""

custom_prompt = PromptTemplate(
    template=custom_prompt_template,
    input_variables=["context", "question"]
)

# QA zinciri
qa_chain = load_qa_chain(
    llm=ChatOpenAI(openai_api_key=openai_api_key),
    chain_type="stuff",
    prompt=custom_prompt
)
qa = RetrievalQA(combine_documents_chain=qa_chain, retriever=retriever)

# FastAPI baÅŸlat
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.post("/chat")
async def chat_endpoint(request: Request):
    data = await request.json()
    message = data.get("question", "")

    if not message:
        return JSONResponse(content={"error": "Soru eksik."}, status_code=400)

    # --- DEBUG ---
    print(f"\nğŸ“¥ Soru alÄ±ndÄ±: {message}")
    relevant_docs = retriever.get_relevant_documents(message)
    print(f"ğŸ” EÅŸleÅŸen dokÃ¼man sayÄ±sÄ±: {len(relevant_docs)}")
    for i, doc in enumerate(relevant_docs[:3], 1):
        print(f"--- DÃ¶kÃ¼man {i} ---\n{doc.page_content[:500]}\n...")
    # --- DEBUG SONU ---

    answer = qa.run(message)
    return {"reply": answer}
