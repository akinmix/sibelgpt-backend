import os
import logging
from fastapi import FastAPI, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from dotenv import load_dotenv

# LangChain ve ilgili kÃ¼tÃ¼phaneler
from langchain_community.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma # Chroma'yÄ± community'den almak daha gÃ¼ncel olabilir
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# --- YapÄ±landÄ±rma ve BaÅŸlangÄ±Ã§ ---

# Loglama ayarlarÄ± (isteÄŸe baÄŸlÄ± ama Ã¶nerilir)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Ortam deÄŸiÅŸkenlerini yÃ¼kle (.env dosyasÄ±ndan)
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    logger.error("OpenAI API anahtarÄ± .env dosyasÄ±nda bulunamadÄ± veya ayarlanmadÄ±!")
    raise ValueError("OPENAI_API_KEY ortam deÄŸiÅŸkeni ayarlanmalÄ±.")

# Sabitler
MARKDOWN_DIRECTORY = "markdowns"
PERSIST_DIRECTORY = "chroma_db" # VektÃ¶r deposunun kaydedileceÄŸi/yÃ¼kleneceÄŸi dizin
CHUNK_SIZE = 500
CHUNK_OVERLAP = 50

# --- Embedding Modeli ve VektÃ¶r Deposu ---

# OpenAI Embedding modeli
try:
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
except Exception as e:
    logger.error(f"OpenAI Embeddings baÅŸlatÄ±lamadÄ±: {e}")
    raise

# ChromaDB'yi YÃ¼kle veya OluÅŸtur (EN Ã–NEMLÄ° DEÄÄ°ÅÄ°KLÄ°K)
db = None
try:
    if os.path.exists(PERSIST_DIRECTORY) and os.listdir(PERSIST_DIRECTORY):
        logger.info(f"Mevcut ChromaDB veritabanÄ± yÃ¼kleniyor: {PERSIST_DIRECTORY}")
        db = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embeddings)
        logger.info("âœ… ChromaDB baÅŸarÄ±yla yÃ¼klendi.")
    else:
        logger.info(f"'{PERSIST_DIRECTORY}' bulunamadÄ± veya boÅŸ. Yeni veritabanÄ± oluÅŸturuluyor...")
        if not os.path.exists(MARKDOWN_DIRECTORY):
             logger.error(f"Markdown dosyalarÄ±nÄ±n olmasÄ± beklenen '{MARKDOWN_DIRECTORY}' dizini bulunamadÄ±!")
             raise FileNotFoundError(f"'{MARKDOWN_DIRECTORY}' dizini mevcut deÄŸil.")

        logger.info(f"'{MARKDOWN_DIRECTORY}' iÃ§indeki .md dosyalarÄ± yÃ¼kleniyor...")
        loader = DirectoryLoader(MARKDOWN_DIRECTORY, glob="*.md", show_progress=True)
        documents = loader.load()

        if not documents:
            logger.warning(f"'{MARKDOWN_DIRECTORY}' iÃ§inde iÅŸlenecek .md dosyasÄ± bulunamadÄ±.")
            # Ä°steÄŸe baÄŸlÄ±: BoÅŸ bir veritabanÄ± oluÅŸturulabilir veya hata verilebilir
            # Åimdilik devam et, ancak uygulama iÅŸlevsiz olabilir.
        else:
            logger.info(f"{len(documents)} adet dÃ¶kÃ¼man yÃ¼klendi.")
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)
            texts = text_splitter.split_documents(documents)
            logger.info(f"DÃ¶kÃ¼manlar {len(texts)} parÃ§aya (chunk) ayrÄ±ldÄ±.")

            logger.info("Embedding'ler oluÅŸturuluyor ve ChromaDB'ye kaydediliyor (Bu iÅŸlem biraz sÃ¼rebilir)...")
            db = Chroma.from_documents(
                documents=texts,
                embedding=embeddings,
                persist_directory=PERSIST_DIRECTORY
            )
            logger.info(f"âœ… ChromaDB oluÅŸturuldu ve '{PERSIST_DIRECTORY}' iÃ§ine kaydedildi.")

except Exception as e:
    logger.error(f"ChromaDB yÃ¼klenirken/oluÅŸturulurken hata oluÅŸtu: {e}", exc_info=True)
    # Uygulama vektÃ¶r deposu olmadan Ã§alÄ±ÅŸamaz, bu yÃ¼zden burada durmak mantÄ±klÄ± olabilir.
    raise

# Retriever'Ä± oluÅŸtur (db nesnesi artÄ±k dolu olmalÄ± veya hata vermiÅŸ olmalÄ±)
if db:
    retriever = db.as_retriever()
    logger.info("Retriever baÅŸarÄ±yla oluÅŸturuldu.")
else:
    logger.error("VeritabanÄ± nesnesi (db) baÅŸlatÄ±lamadÄ±ÄŸÄ± iÃ§in retriever oluÅŸturulamadÄ±.")
    # UygulamanÄ±n bu noktada Ã§alÄ±ÅŸmaya devam etmemesi gerekebilir
    # veya chat endpoint'i bunu kontrol etmeli.
    retriever = None # Hata durumunu belirtmek iÃ§in

# --- Prompt ve QA Zinciri ---

# DetaylÄ± ve yapÄ±landÄ±rÄ±lmÄ±ÅŸ custom prompt
custom_prompt_template = """
Sen, Ä°stanbul Anadolu YakasÄ±â€™nda Ã§alÄ±ÅŸan bir gayrimenkul danÄ±ÅŸmanÄ± olan Sibel Kazan Midilli adÄ±na konuÅŸan dijital asistansÄ±n. KullanÄ±cÄ±dan gelen sorulara, sana saÄŸlanan aÅŸaÄŸÄ±daki baÄŸlam (context) bilgilerine dayanarak mantÄ±klÄ± ve gÃ¼venilir yanÄ±tlar veriyorsun.

Her yanÄ±tÄ±nda ÅŸu kurallara mutlaka uy:

ğŸ“Œ Filtreleme ve MantÄ±ksal Ã–ncelik:
1. KullanÄ±cÄ±nÄ±n belirttiÄŸi semt, oda tipi, fiyat, kat, kredi uygunluÄŸu gibi bilgileri baÄŸlam iÃ§inde ara ve dikkate al.
2. EÄŸer baÄŸlamda tam eÅŸleÅŸen ilan(lar) varsa, Ã¶nce â€œTam olarak aradÄ±ÄŸÄ±nÄ±z kriterlere uygun ÅŸu ilanlarÄ± buldum:â€ diyerek onlarÄ± sun.
3. EÄŸer baÄŸlamda tam eÅŸleÅŸen ilan bulunamazsa, bunu aÃ§Ä±kÃ§a belirt:
   > â€œVerdiÄŸiniz kriterlere tam olarak uyan ilan ÅŸu anda elimdeki verilerde bulunamadÄ±. Ancak benzer olabilecek birkaÃ§ alternatif ÅŸunlar olabilir:â€
4. Benzer ilanlarÄ±, yalnÄ±zca baÄŸlamdaki bilgilerden yola Ã§Ä±karak, konu dÄ±ÅŸÄ±na Ã§Ä±kmadan (Ã¶rneÄŸin yakÄ±n semt, benzer oda sayÄ±sÄ±, yakÄ±n fiyat aralÄ±ÄŸÄ± gibi mantÄ±klÄ± yakÄ±nlÄ±kta) sun. Asla baÄŸlam dÄ±ÅŸÄ± bilgi uydurma.

ğŸ“Œ Cevap FormatÄ± â€“ Her Ä°lanÄ± AÅŸaÄŸÄ±daki Gibi Listele (Bilgi yoksa boÅŸ bÄ±rakma, "BelirtilmemiÅŸ" yaz):
- **Ä°lan No:** (BaÄŸlamdaki ilan no)
- **Lokasyon:** (BaÄŸlamdaki Ä°l/Ä°lÃ§e/Mahalle)
- **Oda SayÄ±sÄ±:** (BaÄŸlamdaki oda sayÄ±sÄ±)
- **mÂ²:** (BaÄŸlamdaki metrekare)
- **Kat:** (BaÄŸlamdaki kat bilgisi)
- **Fiyat:** (BaÄŸlamdaki fiyat)
- **Ekstra:** (BaÄŸlamdaki ek bilgiler - krediye uygun, deniz manzaralÄ±, yeni bina vb. Varsa belirt, yoksa bu satÄ±rÄ± ekleme)

ğŸ“Œ YanÄ±t YapÄ±sÄ±:
- 1. Paragraf: KullanÄ±cÄ±nÄ±n isteÄŸine kÄ±sa bir yanÄ±t (Ã¶rneÄŸin: "Ä°stediÄŸiniz Ã¶zelliklerde 3 ilan buldum." veya "Tam eÅŸleÅŸen ilan bulamadÄ±m ama benzerleri var.")
- 2. Paragraf: Bulunan uygun ilanlar (eÄŸer varsa, yukarÄ±daki formatta, en fazla 3 tane, her biri arasÄ±nda bir boÅŸ satÄ±r bÄ±rakarak).
- 3. Paragraf: Kibar bir kapanÄ±ÅŸ ve kullanÄ±cÄ±yÄ± daha fazla soru sormaya teÅŸvik eden bir cÃ¼mle.

Ã–rnek KapanÄ±ÅŸ:
> Dilersen farklÄ± bir semt veya bÃ¼tÃ§e iÃ§in de arama yapabiliriz ya da mevcut ilanlar hakkÄ±nda daha fazla detay sorabilirsin. NasÄ±l devam etmek istersin?

ğŸ“Œ ÅunlarÄ± Asla Yapma:
- KullanÄ±cÄ±yÄ± dÄ±ÅŸarÄ±daki web sitelerine, baÅŸka danÄ±ÅŸmanlara veya Remax'a yÃ¶nlendirme.
- BaÄŸlamda olmayan bilgileri uydurma veya tutarsÄ±z cevap verme.
- YanÄ±tlarÄ± gereksiz uzun paragraflara boÄŸma.
- "Bilmiyorum", "Emin deÄŸilim" gibi kaÃ§amak veya yetersiz cevaplar verme. Sadece saÄŸlanan baÄŸlamÄ± kullan.

ğŸ“Œ KonuÅŸma TarzÄ±:
- Profesyonel, yardÄ±msever ve samimi.
- GÃ¼ven verici ve bilgili.
- Kibar ve kullanÄ±cÄ± dostu.

BaÄŸlam (Context):
{context}

Soru (Question):
{question}

Cevap:
"""

# Prompt Template oluÅŸtur
prompt = PromptTemplate(
    template=custom_prompt_template,
    input_variables=["context", "question"]
)

# QA Zinciri oluÅŸtur (GÃ¼ncel yÃ¶ntemle)
try:
    llm = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.7) # Temperature ayarÄ±nÄ± deneyebilirsiniz
    if retriever is None:
         raise ValueError("Retriever baÅŸlatÄ±lamadÄ±ÄŸÄ± iÃ§in QA zinciri oluÅŸturulamÄ±yor.")

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff", # Token limitini aÅŸma riskine dikkat!
        retriever=retriever,
        return_source_documents=False, # Kaynak dokÃ¼manlarÄ± dÃ¶ndÃ¼rme (isteÄŸe baÄŸlÄ±)
        chain_type_kwargs={"prompt": prompt}
    )
    logger.info("âœ… RetrievalQA zinciri baÅŸarÄ±yla oluÅŸturuldu.")
except Exception as e:
    logger.error(f"QA Zinciri oluÅŸturulurken hata: {e}", exc_info=True)
    qa_chain = None # Hata durumunu belirt

# --- FastAPI UygulamasÄ± ---

app = FastAPI(
    title="SibelGPT Gayrimenkul AsistanÄ± API",
    description="LangChain ve OpenAI kullanarak emlak sorularÄ±na cevap veren API.",
    version="1.0.0"
)

# CORS AyarlarÄ± (Production iÃ§in allow_origins'i daraltÄ±n)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # Ã–rnek: ["https://www.sibelgpt.com", "http://localhost:3000"]
    allow_credentials=True,
    allow_methods=["POST", "GET"], # Sadece gerekli metodlara izin verin
    allow_headers=["*"], # Veya spesifik baÅŸlÄ±klar: ["Content-Type", "Authorization"]
)

@app.get("/")
async def read_root():
    """ API'nin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶steren basit bir hoÅŸgeldin mesajÄ±. """
    return {"message": "SibelGPT Backend API Ã§alÄ±ÅŸÄ±yor!"}

@app.post("/chat")
async def chat_endpoint(request: Request):
    """ KullanÄ±cÄ±dan gelen sorularÄ± alÄ±r, QA zincirini Ã§alÄ±ÅŸtÄ±rÄ±r ve cevabÄ± dÃ¶ndÃ¼rÃ¼r. """
    if qa_chain is None or retriever is None:
         logger.error("/chat endpoint Ã§aÄŸrÄ±ldÄ± ancak QA zinciri veya retriever hazÄ±r deÄŸil.")
         raise HTTPException(status_code=503, detail="Servis ÅŸu anda hazÄ±r deÄŸil, lÃ¼tfen daha sonra tekrar deneyin.")

    try:
        data = await request.json()
        message = data.get("question") # None dÃ¶nebilir

        if not message or not isinstance(message, str) or not message.strip():
            logger.warning(f"GeÃ§ersiz veya eksik soru alÄ±ndÄ±: {message}")
            raise HTTPException(status_code=400, detail="LÃ¼tfen geÃ§erli bir soru (question) gÃ¶nderin.")

        logger.info(f"ğŸ“¥ Soru alÄ±ndÄ±: {message}")

        # --- DEBUG iÃ§in ilgili dokÃ¼manlarÄ± gÃ¶rme (isteÄŸe baÄŸlÄ±) ---
        # try:
        #     relevant_docs = retriever.get_relevant_documents(message)
        #     logger.info(f"ğŸ” Bulunan ilgili dÃ¶kÃ¼man sayÄ±sÄ±: {len(relevant_docs)}")
        #     for i, doc in enumerate(relevant_docs[:3], 1): # Ä°lk 3 dokÃ¼manÄ± logla
        #         logger.debug(f"--- Ä°lgili DÃ¶kÃ¼man {i} Ä°Ã§eriÄŸi (ilk 300 karakter) ---\n{doc.page_content[:300]}\n...")
        # except Exception as e_retriever:
        #     logger.warning(f"Debug iÃ§in dokÃ¼man alÄ±nÄ±rken hata: {e_retriever}")
        # --- DEBUG SONU ---

        logger.info("QA zinciri Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...")
        # Zinciri Ã§alÄ±ÅŸtÄ±r (DoÄŸru invoke kullanÄ±mÄ±)
        result = qa_chain.invoke({"query": message})
        answer = result.get("result")

        if not answer:
             logger.warning("QA zinciri 'result' anahtarÄ± olmayan bir sonuÃ§ dÃ¶ndÃ¼rdÃ¼.")
             answer = "ÃœzgÃ¼nÃ¼m, sorunuzu iÅŸlerken bir sorun oluÅŸtu." # VarsayÄ±lan cevap

        logger.info(f"âœ… Cevap Ã¼retildi (ilk 100 karakter): {answer[:100]}...")
        return {"reply": answer}

    except HTTPException as http_exc:
        # Zaten bilinen HTTP hatalarÄ±nÄ± tekrar yÃ¼kselt
        raise http_exc
    except Exception as e:
        # Beklenmedik diÄŸer tÃ¼m hatalarÄ± yakala ve logla
        logger.error(f"'/chat' endpoint'inde beklenmedik hata: {e}", exc_info=True)
        # KullanÄ±cÄ±ya genel bir hata mesajÄ± gÃ¶nder
        raise HTTPException(status_code=500, detail="MesajÄ±nÄ±z iÅŸlenirken dahili bir sunucu hatasÄ± oluÅŸtu.")

# --- Uvicorn ile Ã‡alÄ±ÅŸtÄ±rma (opsiyonel, genellikle dÄ±ÅŸarÄ±dan yapÄ±lÄ±r) ---
# Genellikle `uvicorn main:app --reload --host 0.0.0.0 --port 8000` gibi Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r.
# if __name__ == "__main__":
#     import uvicorn
#     logger.info("Uygulama doÄŸrudan Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor (uvicorn)...")
#     uvicorn.run(app, host="0.0.0.0", port=int(os.getenv("PORT", 8000)))
